import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import japanize_matplotlib
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler
from win32cryptcon import szOID_RSA_data

retail = pd.read_excel('C:/Users/23X4002/Desktop/3年生秋/PBL/小売データ.xlsx')
weather= pd.read_csv('C:/Users/23X4002/Desktop/3年生秋/PBL/気象データ.csv',
                     encoding='cp932', skiprows=3)


# ===== データの結合 ======
weather['日付'] = pd.to_datetime(weather['年月日.1'], errors='coerce')
weather = weather.loc[:, ~weather.columns.str.contains(r'\.\d+$')]
weather = weather.drop(columns=['最深積雪(cm)', '平均雲量(10分比)', '年月日'])
weather = weather.drop(index=[0, 1]).reset_index(drop=True)

retail['日付'] = pd.to_datetime(retail['day'])
retail = retail.drop(columns=['day'])

print(retail.head())
print(weather.head())

# weather を retail の行数に合わせて繰り返す
weather_expanded = retail[['日付']].merge(weather, on='日付', how='left')
print(weather_expanded.head())
print(weather_expanded.shape)

merged = pd.merge(retail, weather, on='日付', how='left')


# ===== 広告施策に対するエンコーディング =====
ad_cols = ['SNS', '売場施策', 'TV放映', 'プロモーション']
merged[ad_cols] = merged[ad_cols].fillna('なし')
binary_ad_cols = [col + '_有無' for col in ad_cols]
# 'なし' でない場合は 1 (あり)、'なし' の場合は 0
for original_col, new_col in zip(ad_cols, binary_ad_cols):
    merged[new_col] = (merged[original_col] != 'なし').astype(int)
# エンコード結果を結合し、元の列を削除
data = merged.drop(columns=ad_cols)



# ===== 欠損値の処理 =====
# print(data.isnull().sum())
num_cols = data.select_dtypes(include=[np.number]).columns
print(num_cols)
num_imputer = SimpleImputer(strategy='mean')
data[num_cols] = num_imputer.fit_transform(data[num_cols])
# print(data.isnull().sum())



# ===== 外れ値処理（IQR法） =====
for col in num_cols:
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    # 外れ値を範囲内に収める（クリッピング）
    data[col] = np.clip(data[col], lower, upper)


# ===== 正規化・標準化 ======
exclude_cols = ['price', '売上数', '当店在庫手持週',
                'SNS_有無', '売場施策_有無', 'TV放映_有無', 'プロモーション_有無']
scale_cols = [col for col in num_cols if col not in exclude_cols]
# # --- 標準化（平均0・分散1） ---
# std_scaler = StandardScaler()
# data_std = data.copy()
# data_std[scale_cols] = std_scaler.fit_transform(data[scale_cols])
# --- MinMax正規化（0〜1） ---
mm_scaler = MinMaxScaler()
data_mm = data.copy()
data_mm[scale_cols] = mm_scaler.fit_transform(data[scale_cols])

# print(data_mm.nunique())
# print(data_mm.shape)
# print(data_mm.head())
# print(data_mm.info())
# print(data_mm.describe())




# ===== 目的変数の設定 ======
X = data_mm.drop(columns='売上数')
y = data_mm['売上数']



# ===== データの分割（疑似的層化分割）=====
bins = [0, 25, 50, 100, 150, np.inf]
labels = [0, 1, 2, 3, 4]
y_bins = pd.cut(y, bins=bins, labels=labels, include_lowest=True)
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_idx, test_idx in split.split(X, y_bins):
    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]





# # ===== 可視化 =====
# # ----- 散布図 -----
# for col in num_cols:
#   plt.figure(figsize=(8, 5))
#   sns.scatterplot(x=col, y="売上数", data=data_mm, alpha=0.5)
#   plt.xlabel(col)
#   plt.ylabel("売上数")
#   plt.title(col+"と売上数")
#   plt.grid()
#   plt.show()
# # ----- ヒストグラム -----
# plt.figure(figsize=(8, 5))
# data['売上数'].hist(bins=30)
# plt.xlabel('売上数')
# plt.ylabel('件数')
# plt.title('売上数の分布')
# plt.show()
# # ----- testとtrainの分布確認 -----
# fig, ax = plt.subplots(1, 2, figsize=(10, 4), sharey=True)
# ax[0].hist(y_train, bins=bins, color='skyblue', edgecolor='black')
# ax[0].set_title("Train set 売上数分布")
# ax[1].hist(y_test, bins=bins, color='salmon', edgecolor='black')
# ax[1].set_title("Test set 売上数分布")
# plt.show()


